{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BNN_Larq_Introduction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPS2yg2wI80oKWyv0L3JoQ1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/garrisongys/BNN/blob/master/BNN_Larq_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF89ZUyGDdw_",
        "colab_type": "text"
      },
      "source": [
        "Source from https://docs.larq.dev/larq/tutorials/mnist/\n",
        "First trial of BNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL9Vs4YoBS-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "bea27eef-96d9-46bd-a0e5-b0dae2c52fe9"
      },
      "source": [
        "!pip install larq"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting larq\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/c4/662b325125ec8c52289cf521924041abf0d2c4e2b53b8c628b5eb097a9fd/larq-0.9.3-py3-none-any.whl (58kB)\n",
            "\r\u001b[K     |█████▋                          | 10kB 22.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 30kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 40kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 51kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from larq) (1.18.2)\n",
            "Collecting terminaltables>=3.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from larq) (0.7)\n",
            "Building wheels for collected packages: terminaltables\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15356 sha256=d99c8312bc473cdd0f755a0dcdbaeb127ac2f979fb96ee7e4e93073996afa4cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built terminaltables\n",
            "Installing collected packages: terminaltables, larq\n",
            "Successfully installed larq-0.9.3 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlCY0JyNBs-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import larq as lq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3huis2ACAGO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "59758970-695a-4e78-f4b9-11e418157525"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "\n",
        "# Normalize pixel values to be between -1 and 1\n",
        "train_images, test_images = train_images / 127.5 - 1, test_images / 127.5 - 1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDq9U-B1CDJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# All quantized layers except the first will use the same options\n",
        "kwargs = dict(input_quantizer=\"ste_sign\",\n",
        "              kernel_quantizer=\"ste_sign\",\n",
        "              kernel_constraint=\"weight_clip\")\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# In the first layer we only quantize the weights and not the input\n",
        "model.add(lq.layers.QuantConv2D(32, (3, 3),\n",
        "                                kernel_quantizer=\"ste_sign\",\n",
        "                                kernel_constraint=\"weight_clip\",\n",
        "                                use_bias=False,\n",
        "                                input_shape=(28, 28, 1)))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "\n",
        "model.add(lq.layers.QuantConv2D(64, (3, 3), use_bias=False, **kwargs))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "\n",
        "model.add(lq.layers.QuantConv2D(64, (3, 3), use_bias=False, **kwargs))\n",
        "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(lq.layers.QuantDense(64, use_bias=False, **kwargs))\n",
        "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "model.add(lq.layers.QuantDense(10, use_bias=False, **kwargs))\n",
        "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "model.add(tf.keras.layers.Activation(\"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzuARjyuCR1e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "3596d661-6082-4fe0-ebdb-d72ab3b7b77a"
      },
      "source": [
        "lq.models.summary(model)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+sequential stats------------------------------------------------------------------------------------------+\n",
            "| Layer                  Input prec.           Outputs  # 1-bit  # 32-bit  Memory  1-bit MACs  32-bit MACs |\n",
            "|                              (bit)                        x 1       x 1    (kB)                          |\n",
            "+----------------------------------------------------------------------------------------------------------+\n",
            "| quant_conv2d                     -  (-1, 26, 26, 32)      288         0    0.04           0       194688 |\n",
            "| max_pooling2d                    -  (-1, 13, 13, 32)        0         0       0           0            0 |\n",
            "| batch_normalization              -  (-1, 13, 13, 32)        0        64    0.25           0            0 |\n",
            "| quant_conv2d_1                   1  (-1, 11, 11, 64)    18432         0    2.25     2230272            0 |\n",
            "| max_pooling2d_1                  -    (-1, 5, 5, 64)        0         0       0           0            0 |\n",
            "| batch_normalization_1            -    (-1, 5, 5, 64)        0       128    0.50           0            0 |\n",
            "| quant_conv2d_2                   1    (-1, 3, 3, 64)    36864         0    4.50      331776            0 |\n",
            "| batch_normalization_2            -    (-1, 3, 3, 64)        0       128    0.50           0            0 |\n",
            "| flatten                          -         (-1, 576)        0         0       0           0            0 |\n",
            "| quant_dense                      1          (-1, 64)    36864         0    4.50       36864            0 |\n",
            "| batch_normalization_3            -          (-1, 64)        0       128    0.50           0            0 |\n",
            "| quant_dense_1                    1          (-1, 10)      640         0    0.08         640            0 |\n",
            "| batch_normalization_4            -          (-1, 10)        0        20    0.08           0            0 |\n",
            "| activation                       -          (-1, 10)        0         0       0           ?            ? |\n",
            "+----------------------------------------------------------------------------------------------------------+\n",
            "| Total                                                   93088       468   13.19     2599552       194688 |\n",
            "+----------------------------------------------------------------------------------------------------------+\n",
            "+sequential summary----------------------------+\n",
            "| Total params                      93.6 k     |\n",
            "| Trainable params                  93.1 k     |\n",
            "| Non-trainable params              468        |\n",
            "| Model size                        13.19 KiB  |\n",
            "| Model size (8-bit FP weights)     11.82 KiB  |\n",
            "| Float-32 Equivalent               365.45 KiB |\n",
            "| Compression Ratio of Memory       0.04       |\n",
            "| Number of MACs                    2.79 M     |\n",
            "| Ratio of MACs that are binarized  0.9303     |\n",
            "+----------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mMGnMEYCciF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "70af87d5-4544-4a9c-d7ce-5e5f6a00cdb5"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=64, epochs=6)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.6578 - accuracy: 0.9031\n",
            "Epoch 2/6\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.4760 - accuracy: 0.9615\n",
            "Epoch 3/6\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.4489 - accuracy: 0.9691\n",
            "Epoch 4/6\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.4344 - accuracy: 0.9734\n",
            "Epoch 5/6\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.4294 - accuracy: 0.9759\n",
            "Epoch 6/6\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.4267 - accuracy: 0.9760\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4951 - accuracy: 0.9629\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BXcJL42DFAd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "064a55cc-a161-4444-da31-0b0b7b2b3bd1"
      },
      "source": [
        "print(f\"Test accuracy {test_acc * 100:.2f} %\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy 96.29 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}